{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니코학생은 나이가 20이고 평균은 95.869입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.869입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.87입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.87입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.87입니다\n"
     ]
    }
   ],
   "source": [
    "stname = \"유니코\"; stage=20; stavg=95.869 \n",
    "# 모두 결과 동일\n",
    "print(stname+\"학생은 나이가 \"+str(stage)+\"이고 평균은 \"+str(stavg)+\"입니다\")\n",
    "print(stname, \"학생은 나이가 \", stage, \"이고 평균은 \", stavg, \"입니다\", sep=\"\")\n",
    "print(\"%s학생은 나이가 %d이고 평균은 %.2f입니다\" % (stname, stage, stavg))\n",
    "print(\"{}학생은 나이가 {}이고 평균은 {:.2f}입니다\".format(stname, stage, stavg))\n",
    "print(f\"{stname}학생은 나이가 {stage}이고 평균은 {stavg:.2f}입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니코학생은 나이가 20이고 평균은 95.869입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.87입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.87입니다\n",
      "유니코학생은 나이가 20이고 평균은 95.87입니다\n"
     ]
    }
   ],
   "source": [
    "v1 = stname+\"학생은 나이가 \"+str(stage)+\"이고 평균은 \"+str(stavg)+\"입니다\"\n",
    "v2 = \"%s학생은 나이가 %d이고 평균은 %.2f입니다\" % (stname, stage, stavg)\n",
    "v3 = \"{}학생은 나이가 {}이고 평균은 {:.2f}입니다\".format(stname, stage, stavg)\n",
    "v4 = f\"{stname}학생은 나이가 {stage}이고 평균은 {stavg:.2f}입니다\"\n",
    "print(v1)\n",
    "print(v2)\n",
    "print(v3)\n",
    "print(v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8 (default, Feb 24 2021, 15:54:32) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\jsj\\PYDATAexam\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  pydatavenv    C:\\Users\\jinsujeong\\AppData\\Roaming\\jupyter\\kernels\\pydatavenv\n",
      "  python3       C:\\Users\\jinsujeong\\anaconda3\\share\\jupyter\\kernels\\python3\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list # 현재 인식되고 있는 커널이 무엇이 있는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: 2AD6-42E1\n",
      "\n",
      " c:\\jsj\\PYDATAexam 디렉터리\n",
      "\n",
      "2021-03-24  오후 04:34    <DIR>          .\n",
      "2021-03-24  오후 04:34    <DIR>          ..\n",
      "2021-03-24  오후 04:20    <DIR>          .ipynb_checkpoints\n",
      "2021-03-24  오후 12:59            54,401 exam0.ipynb\n",
      "2021-03-24  오후 04:34            26,883 exam1.ipynb\n",
      "2021-03-24  오후 03:26               850 first.ipynb\n",
      "2021-03-24  오후 03:45               856 second.ipynb\n",
      "               4개 파일              82,990 바이트\n",
      "               3개 디렉터리  86,996,357,120 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir # 현재 워킹 디렉토리의 파일 리스트를 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n",
      "200\n",
      "11\n",
      "OK\n",
      "[ header 정보 ]----------\n",
      "('Server', 'NWS')\n",
      "('Date', 'Wed, 24 Mar 2021 08:25:06 GMT')\n",
      "('Content-Type', 'text/html; charset=UTF-8')\n",
      "('Transfer-Encoding', 'chunked')\n",
      "('Connection', 'close')\n",
      "('Set-Cookie', 'PM_CK_loc=bab2e5e28de04d6f8b9581c819192a55f59dc5e1112c577776c004607c847fb1; Expires=Thu, 25 Mar 2021 08:25:06 GMT; Path=/; HttpOnly')\n",
      "('Cache-Control', 'no-cache, no-store, must-revalidate')\n",
      "('Pragma', 'no-cache')\n",
      "('P3P', 'CP=\"CAO DSP CURa ADMa TAIa PSAa OUR LAW STP PHY ONL UNI PUR FIN COM NAV INT DEM STA PRE\"')\n",
      "('X-Frame-Options', 'DENY')\n",
      "('X-XSS-Protection', '1; mode=block')\n",
      "('Strict-Transport-Security', 'max-age=63072000; includeSubdomains')\n",
      "('Referrer-Policy', 'unsafe-url')\n"
     ]
    }
   ],
   "source": [
    "# 데이터 수집과 관련된 소스 코드\n",
    "import urllib.request\n",
    "res = urllib.request.urlopen(\"http://www.naver.com/\")\n",
    "print(type(res))\n",
    "print(res.status)  # 성공했다는 뜻으로 200 출력\n",
    "print(res.version) # http 프로토콜 버전 의미\n",
    "print(res.msg) # 성공해서 ok\n",
    "res_header = res.getheaders()  # 응답 헤더의 내용을 추출하는 메서드\n",
    "print(\"[ header 정보 ]----------\")\n",
    "for s in res_header :  \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x0000025ADC984BE0>\n",
      "[ header 정보 ]----------\n",
      "('Date', 'Wed, 24 Mar 2021 08:30:08 GMT')\n",
      "('Server', 'Apache/2.2.15 (CentOS)')\n",
      "('Content-Length', '461')\n",
      "('Connection', 'close')\n",
      "('Content-Type', 'text/html')\n",
      "[ body 내용 ]-----------\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<title>Insert title here</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>블럭스타일 태그</h1>\n",
      "<div style=\"background-color:yellow\">테스트입니다1</div>\n",
      "<div>테스트입니다2</div>\n",
      "<div>테스트입니다3</div>\n",
      "<hr>\n",
      "<h1>인라인스타일 태그</h1>\n",
      "<span style=\"background-color:yellow\">테스트입니다1</span>\n",
      "<span>테스트입니다2</span>\n",
      "<span>테스트입니다3</span>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request   # URL 문자열을 가지고 HTTP 요청 수행\n",
    "res = urllib.request.urlopen(\"http://unico2013.dothome.co.kr/crawling/tagstyle.html\")\n",
    "print(res) # 이런 위치에 만들어졌구나 확인\n",
    "print(\"[ header 정보 ]----------\")\n",
    "res_header = res.getheaders()  # 헤더 정보 가져옴\n",
    "for s in res_header :\n",
    "    print(s)\n",
    "print(\"[ body 내용 ]-----------\")\n",
    "#print(res.read()) # 한글은 16진수 코드 값으로 표현된다. 바이트 문자열.\n",
    "#print(type(res.read())) # 바이트 객체\n",
    "print(res.read().decode('utf-8')) # read 메서드를 실행하면 웹서버가 전달한 데이터(응답 바디)를 바이트 열로 읽어들임.\n",
    "# 한글로 들어 있는 경우는 반드시!! decode!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "<class 'http.client.HTTPResponse'>\n",
      "<class 'http.client.HTTPMessage'>\n",
      "https://www.python.org/  페이지의 인코딩 정보 : utf-8\n",
      "<!doctype html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqu\n",
      "===========================================================\n",
      "https://www.daum.net/  페이지의 인코딩 정보 : utf-8\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"ko\" class=\"\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Daum</title>\n",
      "<meta property=\"og:url\" content=\"https://www.daum.net/\">\n",
      "<meta property=\"og:type\" content=\"website\">\n",
      "<meta property=\"og:title\" content=\"Daum\">\n",
      "<meta property=\"og:image\" content=\"//i1.daumcdn.net/svc/image/U03/common_icon/5587C4E4012FCD0001\">\n",
      "<meta property=\"og:description\" content=\"나의 관심 콘텐츠를 가장 즐겁게 볼 수 있는 Daum\">\n",
      "<meta name=\"msapplication-task\" content=\"name=Daum;action-\n",
      "===========================================================\n",
      "https://www.aladin.co.kr/home/welcome.aspx  페이지의 인코딩 정보 : utf-8\n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" >\n",
      "<html>\n",
      "  <head>    \n",
      "      <title id=\"Title\">알라딘</title>\n",
      "      <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
      "\t  <meta content=\"Microsoft Visual Studio .NET 7.1\" name=\"GENERATOR\">\n",
      "\t  <meta content=\"C#\" name=\"CODE_LANGUAGE\">\n",
      "\t  <meta content=\"JavaScript\" name=\"vs_defaultClientScript\">\n",
      "\t  <meta content=\"http://schemas.microsoft.com/intellisense/ie5\" name=\"vs_targetSchema\">\n",
      "      <meta http-equiv=\"\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "print(\"===========================================================\")\n",
    "url = 'https://www.python.org/'  # 파이썬 홈페이지\n",
    "f = urllib.request.urlopen(url)\n",
    "print(type(f))\n",
    "print(type(f.info()))\n",
    "encoding = f.info().get_content_charset()\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "text = f.read(500).decode(encoding) # 앞에서부터 500바이트 만큼만 읽겠다.\n",
    "print(text)\n",
    "print(\"===========================================================\")\n",
    "\n",
    "url = 'https://www.daum.net/'   \n",
    "f = urllib.request.urlopen(url)\n",
    "encoding = f.info().get_content_charset()\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "text = f.read(500).decode(encoding)  # 500바이트 만큼만 읽겠다.\n",
    "print(text)\n",
    "print(\"===========================================================\")\n",
    "\n",
    "url = 'https://www.aladin.co.kr/home/welcome.aspx'   # 알라딘 홈페이지\n",
    "f = urllib.request.urlopen(url)\n",
    "encoding = f.info().get_content_charset()\n",
    "print(url, ' 페이지의 인코딩 정보 :', encoding)\n",
    "\n",
    "text = f.read(500).decode(encoding)\n",
    "print(text)\n",
    "print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urlencode\n",
    "print(\"[ URL 문자열 정보 추출 1 ]\")\n",
    "url1 = urlparse('https://movie.daum.net/moviedb/main?movieId=93252')\n",
    "print(\"타입정보 : \",type(url1))\n",
    "print(\"도메인정보 : \",url1.netloc) \n",
    "print(\"패스정보 : \",url1.path)\n",
    "print(\"쿼리정보 : \",url1.query) \n",
    "print(\"스킴정보 : \",url1.scheme)\n",
    "print(\"포트정보 : \",url1.port)\n",
    "print(\"프래그먼트정보 : \",url1.fragment)\n",
    "print(\"URL 문자열정보 : \",url1.geturl())\n",
    "print(\"urllib.parse.ParseResult 객체정보 : \",url1)\n",
    "print(\"\\n[ URL 문자열 정보 추출 2 ]\")\n",
    "url2 = urlparse('https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object')\n",
    "print(\"도메인정보 : \",url2.netloc) \n",
    "print(\"패스정보 : \", url2.path)  \n",
    "print(\"쿼리정보 : \",url2.query)\n",
    "print(\"스킴정보 : \",url2.scheme)\n",
    "print(\"포트정보 : \",url2.port)\n",
    "print(\"프래그먼트정보 : \",url2.fragment)\n",
    "print(\"URL 문자열정보 : \",url2.geturl())\n",
    "print(\"urllib.parse.ParseResult 객체정보 : \",url2)\n",
    "\n",
    "print(\"\\n[ Query문자열 또는 요청 파라미터 인코딩 ]\")\n",
    "params1 = urlencode({'number': 12524, 'type': 'issue', 'action': 'show'})\n",
    "print(params1)\n",
    "params2 = urlencode({'addr': '서울시 강남구 역삼동'})\n",
    "print(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "params = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "print(\"URL 인코딩 규칙이 적용된 문자열 : %s\" % params)\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/get.php?%s\" % params\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "print(\"URL 인코딩 규칙이 적용된 문자열 : %s\" % data)\n",
    "postdata = data.encode('ascii')\n",
    "print(\"변환된 바이트 문자열 : %s\" % postdata)\n",
    "url = \"http://unico2013.dothome.co.kr/crawling/post.php\"\n",
    "with urllib.request.urlopen(url, postdata) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "data = urllib.parse.urlencode({'name': '유니코', 'age': 10})\n",
    "postdata = data.encode('ascii')\n",
    "req = urllib.request.Request(url='http://unico2013.dothome.co.kr/crawling/post.php',\n",
    "            data=postdata)\n",
    "print(req)\n",
    "with urllib.request.urlopen(req) as f:\n",
    "    print(f.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.request('get', 'http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n",
    "print('----------------------------------------------------------')\n",
    "r = requests.request('head', 'http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n",
    "print('----------------------------------------------------------')\n",
    "r = requests.request('post', 'http://unico2013.dothome.co.kr/crawling/post.php', data= {'name':'백도', 'age' : 12})\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "r.encoding = 'utf-8'\n",
    "print(type(r))\n",
    "print(r.headers)\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.head('http://unico2013.dothome.co.kr/crawling/exam.html')\n",
    "print(type(r))\n",
    "print(r.headers)\n",
    "if r.text :\n",
    "    print(r.text)\n",
    "else :\n",
    "    print('응답된 콘텐츠가 없어요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "dicdata = {'key1': 'value1', 'key2': 'value2'}\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/get.php'\n",
    "r = requests.get(urlstr, params=dicdata)\n",
    "print(r.url)\n",
    "print('------------------------------------')\n",
    "dicdata = {'key1': 'value1', 'key2': ['value2', 'value3']}\n",
    "r = requests.request('GET', urlstr, params=dicdata)\n",
    "print(r.url)\n",
    "print('------------------------------------')\n",
    "tupledata = [('key1', 'value1'), ('key1', 'value2')]\n",
    "r = requests.get(urlstr, params=tupledata)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urlstr = 'http://unico2013.dothome.co.kr/crawling/get.php'\n",
    "r = requests.get(urlstr)\n",
    "print(r.text)\n",
    "print('------------------------------------')\n",
    "r.encoding = 'utf-8'\n",
    "print(r.text)\n",
    "print('------------------------------------')\n",
    "print(r.content)\n",
    "print('------------------------------------')\n",
    "print(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "r = requests.get('http://unico2013.dothome.co.kr/image/flower.jpg')\n",
    "i = Image.open(BytesIO(r.content))\n",
    "print(type(i))\n",
    "i.save(\"c:/Temp/test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <title>Test BeautifulSoup</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>테스트</h1>\n",
    "    </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(bs.prettify())\n",
    "print(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "          <ul>\n",
    "               <li>테스트1<strong>강조</strong></li>\n",
    "               <li>테스트2</li>\n",
    "               <li>테스트3</li>\n",
    "          </ul>\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs.title), ':', bs.title)\n",
    "print(type(bs.title.name), ':', bs.title.name)\n",
    "print(type(bs.title.string), ':', bs.title.string)\n",
    "print('-------------------------')\n",
    "print(type(bs.p['align']), ':', bs.p['align'])\n",
    "print(type(bs.img['src']), ':', bs.img['src'])\n",
    "print(type(bs.img.attrs), ':', bs.img.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "     <head>\n",
    "          <meta charset='utf-8'>\n",
    "          <title>Test BeautifulSoup</title>\n",
    "     </head>\n",
    "     <body>\n",
    "          <p align=\"center\">P태그의 컨텐트</p>\n",
    "          <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"300\">\n",
    "          <ul>\n",
    "               <li>테스트1<strong>강조</strong></li>\n",
    "               <li>테스트2</li>\n",
    "               <li>테스트3</li>\n",
    "          </ul>\n",
    "     </body>\n",
    "</html> \"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(\"[ string 속성 ]\")\n",
    "print(type(bs.p.string), ':', bs.p.string)\n",
    "print(type(bs.ul.string), ':', bs.ul.string)\n",
    "print(type(bs.ul.li.string), ':', bs.ul.li.string)\n",
    "print(type(bs.ul.li.strong.string), ':', bs.ul.li.strong.string)\n",
    "print(\"[ text 속성 ]\")\n",
    "print(type(bs.p.text), ':', bs.p.text)\n",
    "print(type(bs.ul.text), ':', bs.ul.text)\n",
    "print(type(bs.ul.li.text), ':', bs.ul.li.text)\n",
    "print(type(bs.ul.li.strong.text), ':', bs.ul.li.strong.text)\n",
    "print(\"[ contents 속성 ]\")\n",
    "print(type(bs.p.contents), ':', bs.p.contents)\n",
    "print(type(bs.ul.contents), ':', bs.ul.contents)\n",
    "print(type(bs.ul.li.contents), ':', bs.ul.li.contents)\n",
    "print(type(bs.ul.li.strong.contents), ':', bs.ul.li.strong.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "     <meta charset='utf-8'>\n",
    "     <title>Test BeautifulSoup</title>\n",
    "  </head>\n",
    "  <body>\n",
    "     <p align=\"center\"> text contents </p>\n",
    "     <p align=\"right\">  text contents 2 </p>\n",
    "     <p align=\"left\">   text contents 3 </p>\n",
    "     <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\">\n",
    "     <div>\n",
    "       <p>text contents 4</p> \n",
    "     </div>\n",
    "  </body>\n",
    "</html> \"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html_doc, 'html.parser')\n",
    "print(type(bs.find('p')))\n",
    "print(type(bs.find_all('p')))\n",
    "print(\"---------------------------------\")\n",
    "print(bs.find('title'))\n",
    "print(bs.find('p'))\n",
    "print(bs.find('img'))\n",
    "print(\"---------------------------------\")\n",
    "ptags = bs.find_all('p')\n",
    "print(ptags)\n",
    "print(\"----------------\")\n",
    "for tag in ptags :\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "     <meta charset='utf-8'>\n",
    "     <title>Test BeautifulSoup</title>\n",
    "  </head>\n",
    "  <body>\n",
    "     <p align=\"center\"> text contents </p>\n",
    "     <p align=\"right\" class=\"myp\">  text contents 2 </p>\n",
    "     <p align=\"left\" a=\"b\">   text contents 3 </p>\n",
    "     <img src=\"http://unico2013.dothome.co.kr/image/flower.jpg\" width=\"500\">\n",
    "  </body>\n",
    "</html> \"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(bs.find('p', align=\"center\"))\n",
    "print(bs.find('p', class_=\"myp\"))\n",
    "print(bs.find('p', align=\"left\"))\n",
    "print(\"-------------------------------------\")\n",
    "print(bs.find('p', attrs={\"align\":\"center\"}))\n",
    "print(bs.find('p', attrs={\"align\":\"right\", \"class\":\"myp\"}))\n",
    "print(bs.find('p', attrs={\"align\":\"left\"}))\n",
    "\n",
    "pdom = bs.find('p', align=\"left\")\n",
    "print(\"[\"+pdom.text+\"]\")\n",
    "print(\"[\"+pdom.get_text(strip=True)+\"]\")\n",
    "print(\"[\"+pdom.string.strip()+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "req = requests.get('http://unico2013.dothome.co.kr/crawling/exercise_css.html')\n",
    "html = req.content\n",
    "print(type(html))\n",
    "html = html.decode('utf-8')\n",
    "#print(html)\n",
    "print(\"==============================\")\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "title = bs.select('h1')\n",
    "title1 = bs.select('#f_subtitle')\n",
    "title2 = bs.select('.subtitle')\n",
    "title3 = bs.select('aside > h2')\n",
    "img = bs.select('[src]')\n",
    "print(title)\n",
    "print(type(title))\n",
    "print(type(title[0]))\n",
    "print(\"<h1>태그의 갯수 : %d \" %len(title))\n",
    "print(\"f_subtitle이라는 id 속성을 갖는 태그 갯수 : %d \" %len(title1))\n",
    "print(\"subtitle이라는 class 속성을 갖는 태그 갯수 : %d \" %len(title2))\n",
    "print(\"aside 태그의 <h2> 자식 태그 갯수 : %d \" %len(title3))\n",
    "print(\"src 속성을 갖는 태그 갯수 : %d \" %len(img))\n",
    "\n",
    "for content in title:\n",
    "    print(content.string)\n",
    "print(\"------------------------------\")\n",
    "for content in title1:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in title2:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in title3:\n",
    "    print(content.text)\n",
    "print(\"------------------------------\")\n",
    "for content in img:\n",
    "   print(content[\"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "req = requests.get('http://movie.naver.com/movie/point/af/list.nhn?page=1')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "titles = soup.select('.movie')\n",
    "points = soup.select('td.title > div > em')\n",
    "reviews = soup.select('td.title')\n",
    "movie_title = []\n",
    "movie_point = []\n",
    "movie_review = [] \n",
    "\n",
    "for dom in titles:\n",
    "    movie_title.append(dom.text)\n",
    "for dom in points:\n",
    "    movie_point.append(dom.text)\n",
    "for dom in reviews:\n",
    "    content = dom.contents[6] \n",
    "    #content=re.sub(\"신고\", '', content)\n",
    "    content=re.sub(\"[\\n\\t]\", '', content)    \n",
    "    movie_review.append(content)\n",
    "commentLength = len(movie_title)   \n",
    "for i in range(commentLength):\n",
    "    print(\"영화 제목 : \" + movie_title[i])\n",
    "    print(\"평점 : \" + movie_point[i])\n",
    "    print(\"리뷰글 : \" + movie_review[i])\n",
    "    print(\"-----------------------------------------\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "for n in range(1,31):\n",
    "    req = requests.get('http://movie.naver.com/movie/point/af/list.nhn?page='+str(n))\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    titles = soup.select('.movie' )\n",
    "    points = soup.select('td.title > div > em')\n",
    "    reviews = soup.select('td.title')\n",
    "    movie_title = []\n",
    "    movie_point = []\n",
    "    movie_review = [] \n",
    "    for dom in titles:\n",
    "        movie_title.append(dom.text)\n",
    "    for dom in points:\n",
    "        movie_point.append(dom.text)\n",
    "    for dom in reviews:\n",
    "        content = dom.contents[6]\n",
    "        #content=re.sub(\"신고\", '', content)\n",
    "        content=re.sub(\"[\\n\\t]\", '', content)\n",
    "        movie_review.append(content)\n",
    "\n",
    "    commentLength = len(movie_title)   \n",
    "    for i in range(commentLength):\n",
    "        print(movie_point[i] + \",\"+movie_title[i]+\",\"+movie_review[i])\n",
    "    print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "title = []\n",
    "link = []\n",
    "urlstr = 'http://www.yes24.com/SearchCorner/Search?domain=BOOK&query=python'\n",
    "r = requests.get(urlstr)\n",
    "#r.encoding = \"utf-8\"\n",
    "bs = BeautifulSoup(r.text, 'html.parser')\n",
    "titleList = bs.select('p.goods_name.goods_icon > a > strong')\n",
    "linklList = bs.select('p.goods_name.goods_icon > a')\n",
    "\n",
    "for titleDom in titleList:\n",
    "    title.append(titleDom.string)\n",
    "for linkDom in linklList:\n",
    "    link.append(linkDom[\"href\"])\n",
    "\n",
    "print(\"-- 도서 제목 --\")\n",
    "print(title)\n",
    "print(\"-- 도서 링크 URL --\")\n",
    "print(link)\n",
    "with open('booklink.csv', \"wt\", encoding=\"utf-8\") as f:\n",
    "    f.write('booktitle,booklink\\n')  \n",
    "    for i in range(len(title)):\n",
    "        f.write(title[i]+\",\"+link[i]+'\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import io\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=108\"\n",
    "savename = \"C:/Temp/forecast.xml\"\n",
    "req.urlretrieve(url, savename)\n",
    "\n",
    "xml = open(savename, \"r\", encoding=\"utf-8\").read()\n",
    "soup = BeautifulSoup(xml, 'html.parser')\n",
    "\n",
    "info = {}\n",
    "for location in soup.find_all(\"location\"):\n",
    "    loc = location.find('city').string\n",
    "    min_w = location.find_all('tmn')\n",
    "    max_w = location.find_all('tmx')\n",
    "    weather = [a.string+\"~\"+b.string for a, b in zip(min_w, max_w)]\n",
    "\n",
    "    if not (loc in info):\n",
    "        info[loc] = []\n",
    "    for data in weather:\n",
    "        info[loc].append(data)\n",
    "print(info)\n",
    "\n",
    "with open('C:/Temp/forecast.txt', \"wt\", encoding=\"utf-8\") as f:\n",
    "    for loc in sorted(info.keys()):\n",
    "        f.write(str(loc)+'\\n')\n",
    "        for name in info[loc]:\n",
    "            f.write('\\t'+str(name)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "\n",
    "#User-Agent를 조작하는 경우 \n",
    "hdr = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '+ \n",
    "        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.80 Safari/537.36'}\n",
    "\n",
    "req = urllib.request.Request('http://unico2013.dothome.co.kr/crawling/header.php', headers = hdr)\n",
    "#req = urllib.request.Request('http://unico2013.dothome.co.kr/crawling/header.php')\n",
    "data = urllib.request.urlopen(req).read()\n",
    "print(data)\n",
    "#page = data.decode('utf-8', 'ignore')\n",
    "res_content = json.loads(data)\n",
    "\n",
    "print(res_content[\"result\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
